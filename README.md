# Medical Visual Question Answering (VQA) Analysis

This is an educational research project focused on evaluating different Deep Learning architectures for **Visual Question Answering** in the medical domain. Using the **VQA-RAD** dataset, we compare a traditional discriminative approach with a modern generative approach.

## ðŸ“Œ Project Overview
The goal of this project is to build a model that can understand a medical image (X-ray, CT, MRI) and provide a relevant answer to a natural language question. We explore two distinct methodologies:

1.  **Method 1: CNN + BERT (Classification)**
    * **Visual Stream:** ResNet-50 backbone for feature extraction.
    * **Textual Stream:** BERT (Bidirectional Encoder Representations from Transformers) for question understanding.
    * **Mechanism:** Multimodal fusion followed by a classification head.
    * **Best for:** Closed-ended questions (Yes/No).

2.  **Method 2: BLIP-1 (Generative)**
    * **Architecture:** Bootstrapping Language-Image Pre-training.
    * **Mechanism:** An encoder-decoder transformer model that generates answers token-by-token.
    * **Best for:** Open-ended descriptive questions and complex clinical reasoning.

---

## ðŸ“‚ Project Structure

```text
medical-vqa-project/
â”œâ”€â”€ data/                   # Dataset documentation and loading instructions
â”‚   â””â”€â”€ README.md           # Links to Hugging Face and data schema
â”œâ”€â”€ notebooks/              # Interactive Jupyter/Colab notebooks
â”‚   â”œâ”€â”€ 01_cnn_bert_vqa.ipynb   # Implementation of Method 1 (Classification)
â”‚   â””â”€â”€ 02_blip_vqa.ipynb       # Implementation of Method 2 (Generative BLIP)
â”œâ”€â”€ src/                    # Modular source code
â”‚   â”œâ”€â”€ datasets.py         # Custom Dataset classes and medical-safe augmentations
â”‚   â”œâ”€â”€ models.py           # Model architectures for CNN+BERT and BLIP loaders
â”‚   â””â”€â”€ utils.py            # Utility functions for VRAM management and plotting
â”œâ”€â”€ checkpoints/            # Local storage for trained model weights (.pth)
â”œâ”€â”€ requirements.txt        # Python dependencies (Torch, Transformers, etc.)
â”œâ”€â”€ .gitignore              # Rules to exclude large weights and cache folders
â””â”€â”€ README.md               # Main project documentation